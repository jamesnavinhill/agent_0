<br />

OUR MOST INTELLIGENT MODEL

## Gemini 3 Pro

The best model in the world for multimodal understanding, and our most powerful agentic and vibe-coding model yet, delivering richer visuals and deeper interactivity, all built on a foundation of state-of-the-art reasoning.

### Expand to learn more

[Try in Google AI Studio](https://aistudio.google.com?model=gemini-3-pro-preview)

#### Model details

### Gemini 3 Pro Preview

| Property | Description |
|---|---|
| id_cardModel code | `gemini-3-pro-preview` |
| saveSupported data types | **Inputs** Text, Image, Video, Audio, and PDF **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 65,536 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - `Preview: gemini-3-pro-preview` |
| calendar_monthLatest update | November 2025 |
| cognition_2Knowledge cutoff | January 2025 |

### Gemini 3 Pro Image Preview

| Property | Description |
|---|---|
| id_cardModel code | `gemini-3-pro-image-preview` |
| saveSupported data types | **Inputs** Image and Text **Output** Image and Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 65,536 **Output token limit** 32,768 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Not supported **Code execution** Not supported **File search** Not supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - `Preview: gemini-3-pro-image-preview` |
| calendar_monthLatest update | November 2025 |
| cognition_2Knowledge cutoff | January 2025 |

OUR MOST BALANCED MODEL, DESIGNED TO SCALE

## Gemini 3 Flash

Our most balanced model built for speed, scale, and frontier intelligence.

### Expand to learn more

[Try in Google AI Studio](https://aistudio.google.com?model=gemini-3-flash-preview)

#### Model details

### Gemini 3 Flash Preview

| Property | Description |
|---|---|
| id_cardModel code | `gemini-3-flash-preview` |
| saveSupported data types | **Inputs** Text, Image, Video, Audio, and PDF **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 65,536 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - `Preview: gemini-3-flash-preview` |
| calendar_monthLatest update | December 2025 |
| cognition_2Knowledge cutoff | January 2025 |

FAST AND INTELLIGENT

## Gemini 2.5 Flash

Our best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.

### Expand to learn more

[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash)

#### Model details

### Gemini 2.5 Flash

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-flash` |
| saveSupported data types | **Inputs** Text, images, video, audio **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 65,536 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Stable: `gemini-2.5-flash` |
| calendar_monthLatest update | June 2025 |
| cognition_2Knowledge cutoff | January 2025 |

### Gemini 2.5 Flash Preview

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-flash-preview-09-2025` |
| saveSupported data types | **Inputs** Text, images, video, audio **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 65,536 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL Context** Supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Preview: `gemini-2.5-flash-preview-09-2025` |
| calendar_monthLatest update | September 2025 |
| cognition_2Knowledge cutoff | January 2025 |

### Gemini 2.5 Flash Image

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-flash-image` |
| saveSupported data types | **Inputs** Images and text **Output** Images and text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 65,536 **Output token limit** 32,768 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Not Supported **File search** Not Supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Supported **Live API** Not Supported **Search grounding** Not Supported **Structured outputs** Supported **Thinking** Not Supported **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Stable: `gemini-2.5-flash-image` - Deprecated: `gemini-2.5-flash-image-preview` |
| calendar_monthLatest update | October 2025 |
| cognition_2Knowledge cutoff | June 2025 |

### Gemini 2.5 Flash Live

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-flash-native-audio-preview-12-2025` |
| saveSupported data types | **Inputs** Audio, video, text **Output** Audio and text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 131,072 **Output token limit** 8,192 |
| handymanCapabilities | **Audio generation** Supported **Batch API** Not supported **Caching** Not supported **Code execution** Not supported **File search** Not Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Supported **Search grounding** Supported **Structured outputs** Not supported **Thinking** Supported **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Preview: `gemini-2.5-flash-native-audio-preview-12-2025` - Preview: `gemini-2.5-flash-native-audio-preview-09-2025` |
| calendar_monthLatest update | September 2025 |
| cognition_2Knowledge cutoff | January 2025 |

### Gemini 2.5 Flash TTS

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-flash-preview-tts` |
| saveSupported data types | **Inputs** Text **Output** Audio |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 8,192 **Output token limit** 16,384 |
| handymanCapabilities | **Audio generation** Supported **Batch API** Supported **Caching** Not supported **Code execution** Not supported **File search** Not Supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Not supported **Structured outputs** Not supported **Thinking** Not supported **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - `gemini-2.5-flash-preview-tts` |
| calendar_monthLatest update | December 2025 |

ULTRA FAST

## Gemini 2.5 Flash-Lite

Our fastest flash model optimized for cost-efficiency and high throughput.

### Expand to learn more

[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-flash-lite)

#### Model details

### Gemini 2.5 Flash-Lite

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-flash-lite` |
| saveSupported data types | **Inputs** Text, image, video, audio, PDF **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 65,536 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Stable: `gemini-2.5-flash-lite` |
| calendar_monthLatest update | July 2025 |
| cognition_2Knowledge cutoff | January 2025 |

### Gemini 2.5 Flash-Lite Preview

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-flash-lite-preview-09-2025` |
| saveSupported data types | **Inputs** Text, image, video, audio, PDF **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 65,536 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Preview: `gemini-2.5-flash-lite-preview-09-2025` |
| calendar_monthLatest update | September 2025 |
| cognition_2Knowledge cutoff | January 2025 |

OUR ADVANCED THINKING MODEL

## Gemini 2.5 Pro

Our state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.

### Expand to learn more

[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.5-pro)

#### Model details

### Gemini 2.5 Pro

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-pro` |
| saveSupported data types | **Inputs** Audio, images, video, text, and PDF **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 65,536 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Supported **Function calling** Supported **Grounding with Google Maps** Supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Supported **URL context** Supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - `Stable: gemini-2.5-pro` |
| calendar_monthLatest update | June 2025 |
| cognition_2Knowledge cutoff | January 2025 |

### Gemini 2.5 Pro TTS

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.5-pro-preview-tts` |
| saveSupported data types | **Inputs** Text **Output** Audio |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 8,192 **Output token limit** 16,384 |
| handymanCapabilities | **Audio generation** Supported **Batch API** Supported **Caching** Not supported **Code execution** Not supported **File search** Not Supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Not supported **Structured outputs** Not supported **Thinking** Not supported **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - `gemini-2.5-pro-preview-tts` |
| calendar_monthLatest update | December 2025 |

<br />

## Previous Gemini models

OUR SECOND GENERATION WORKHORSE MODEL

## Gemini 2.0 Flash

Our second generation workhorse model, with a 1 million token context window.

### Expand to learn more

Gemini 2.0 Flash delivers next-gen features and improved capabilities,
including superior speed, native tool use, and a 1M token
context window.

[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.0-flash)

#### Model details

### Gemini 2.0 Flash

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.0-flash` |
| saveSupported data types | **Inputs** Audio, images, video, and text **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 8,192 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Supported **File search** Not supported **Function calling** Supported **Grounding with Google Maps** Supported **Image generation** Not supported **Live API** Not supported **Search grounding** Supported **Structured outputs** Supported **Thinking** Experimental **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Latest: `gemini-2.0-flash` - Stable: `gemini-2.0-flash-001` - Experimental: `gemini-2.0-flash-exp` |
| calendar_monthLatest update | February 2025 |
| cognition_2Knowledge cutoff | August 2024 |

### Gemini 2.0 Flash Image

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.0-flash-preview-image-generation` |
| saveSupported data types | **Inputs** Audio, images, video, and text **Output** Text and images |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 32,768 **Output token limit** 8,192 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Not Supported **File search** Not supported **Function calling** Not supported **Grounding with Google Maps** Not supported **Image generation** Supported **Live API** Not Supported **Search grounding** Not Supported **Structured outputs** Supported **Thinking** Not Supported **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Preview: `gemini-2.0-flash-preview-image-generation` - gemini-2.0-flash-preview-image-generation is not currently supported in a number of countries in Europe, Middle East \& Africa |
| calendar_monthLatest update | May 2025 |
| cognition_2Knowledge cutoff | August 2024 |

OUR SECOND GENERATION FAST MODEL

## Gemini 2.0 Flash-Lite

Our second generation small workhorse model, with a 1 million token context window.

### Expand to learn more

A Gemini 2.0 Flash model optimized for cost efficiency and low latency.

[Try in Google AI Studio](https://aistudio.google.com?model=gemini-2.0-flash-lite)

#### Model details

| Property | Description |
|---|---|
| id_cardModel code | `gemini-2.0-flash-lite` |
| saveSupported data types | **Inputs** Audio, images, video, and text **Output** Text |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 1,048,576 **Output token limit** 8,192 |
| handymanCapabilities | **Audio generation** Not supported **Batch API** Supported **Caching** Supported **Code execution** Not supported **File search** Not supported **Function calling** Supported **Grounding with Google Maps** Not supported **Image generation** Not supported **Live API** Not supported **Search grounding** Not supported **Structured outputs** Supported **Thinking** Not Supported **URL context** Not supported |
| 123Versions | Read the [model version patterns](https://ai.google.dev/gemini-api/docs/models/gemini#model-versions) for more details. - Latest: `gemini-2.0-flash-lite` - Stable: `gemini-2.0-flash-lite-001` |
| calendar_monthLatest update | February 2025 |
| cognition_2Knowledge cutoff | August 2024 |

<br />

## Model version name patterns

Gemini models are available in either *stable* , *preview* , *latest* , or
*experimental* versions.
| **Note:** The following list refers to the model string naming convention as of September, 2025. Models released prior to that may have different naming conventions. Refer to the exact model string if you are using an older model.

### Stable

Points to a specific stable model. Stable models usually don't change. Most
production apps should use a specific stable model.

For example: `gemini-2.5-flash`.

### Preview

Points to a preview model which may be used for production. Preview models will
typically have billing enabled, might come with more restrictive rate limits and
will be deprecated with at least 2 weeks notice.

For example: `gemini-2.5-flash-preview-09-2025`.

### Latest

Points to the latest release for a specific model variation. This can be a
stable, preview or experimental release. This alias will get hot-swapped with
every new release of a specific model variation. A **2-week notice** will
be provided through email before the version behind latest is changed.

For example: `gemini-flash-latest`.

### Experimental

Points to an experimental model which will typically be not be suitable for
production use and come with more restrictive rate limits. We release
experimental models to gather feedback and get our latest updates into the hands
of developers quickly.

Experimental models are not stable and availability of model endpoints is
subject to change.

## Model deprecations

For information about model deprecations, visit the [Gemini deprecations](https://ai.google.dev/gemini-api/docs/deprecations) page.

# Imagen Models

## Imagen 2.0 Flash<br />

Imagen is Google's high-fidelity image generation model, capable of generating
realistic and high quality images from text prompts. All generated images
include a SynthID watermark. To learn more about the available Imagen model
variants, see the [Model versions](https://ai.google.dev/gemini-api/docs/imagen#model-versions) section.
| **Note:** You can also generate images with Gemini's built-in multimodal capabilities. See the [Image generation
| guide](https://ai.google.dev/gemini-api/docs/image-generation) for details.

## Generate images using the Imagen models

This example demonstrates generating images with an [Imagen model](https://deepmind.google/technologies/imagen-3/):  

### Python

    from google import genai
    from google.genai import types
    from PIL import Image
    from io import BytesIO

    client = genai.Client()

    response = client.models.generate_images(
        model='imagen-4.0-generate-001',
        prompt='Robot holding a red skateboard',
        config=types.GenerateImagesConfig(
            number_of_images= 4,
        )
    )
    for generated_image in response.generated_images:
      generated_image.image.show()

### JavaScript

    import { GoogleGenAI } from "@google/genai";
    import * as fs from "node:fs";

    async function main() {

      const ai = new GoogleGenAI({});

      const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt: 'Robot holding a red skateboard',
        config: {
          numberOfImages: 4,
        },
      });

      let idx = 1;
      for (const generatedImage of response.generatedImages) {
        let imgBytes = generatedImage.image.imageBytes;
        const buffer = Buffer.from(imgBytes, "base64");
        fs.writeFileSync(`imagen-${idx}.png`, buffer);
        idx++;
      }
    }

    main();

### Go

    package main

    import (
      "context"
      "fmt"
      "os"
      "google.golang.org/genai"
    )

    func main() {

      ctx := context.Background()
      client, err := genai.NewClient(ctx, nil)
      if err != nil {
          log.Fatal(err)
      }

      config := &genai.GenerateImagesConfig{
          NumberOfImages: 4,
      }

      response, _ := client.Models.GenerateImages(
          ctx,
          "imagen-4.0-generate-001",
          "Robot holding a red skateboard",
          config,
      )

      for n, image := range response.GeneratedImages {
          fname := fmt.Sprintf("imagen-%d.png", n)
              _ = os.WriteFile(fname, image.Image.ImageBytes, 0644)
      }
    }

### REST

    curl -X POST \
        "https://generativelanguage.googleapis.com/v1beta/models/imagen-4.0-generate-001:predict" \
        -H "x-goog-api-key: $GEMINI_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
            "instances": [
              {
                "prompt": "Robot holding a red skateboard"
              }
            ],
            "parameters": {
              "sampleCount": 4
            }
          }'

![AI-generated image of a robot holding a red skateboard](https://ai.google.dev/static/gemini-api/docs/images/robot-skateboard.png) AI-generated image of a robot holding a red skateboard

### Imagen configuration

Imagen supports English only prompts at this time and the following parameters:
| **Note:** Naming conventions of parameters vary by programming language.

- `numberOfImages`: The number of images to generate, from 1 to 4 (inclusive). The default is 4.
- `imageSize`: The size of the generated image. This is only supported for the Standard and Ultra models. The supported values are `1K` and `2K`. Default is `1K`.
- `aspectRatio`: Changes the aspect ratio of the generated image. Supported values are `"1:1"`, `"3:4"`, `"4:3"`, `"9:16"`, and `"16:9"`. The default is `"1:1"`.
- `personGeneration`: Allow the model to generate images of people. The
  following values are supported:

  - `"dont_allow"`: Block generation of images of people.
  - `"allow_adult"`: Generate images of adults, but not children. This is the default.
  - `"allow_all"`: Generate images that include adults and children.

  | **Note:** The `"allow_all"` parameter value is not allowed in EU, UK, CH, MENA locations.

## Imagen prompt guide

This section of the Imagen guide shows you how modifying a text-to-image prompt
can produce different results, along with examples of images you can create.

### Prompt writing basics

| **Note:** Maximum prompt length is 480 tokens.

A good prompt is descriptive and clear, and makes use of meaningful keywords and
modifiers. Start by thinking of your **subject** , **context** , and **style**.
![Prompt with subject, context, and style emphasized](https://ai.google.dev/static/gemini-api/docs/images/imagen/style-subject-context.png) Image text: A *sketch* (**style** ) of a *modern apartment building* (**subject** ) surrounded by *skyscrapers* (**context and background**).

1. **Subject** : The first thing to think about with any prompt is the
   *subject*: the object, person, animal, or scenery you want an image of.

2. **Context and background:** Just as important is the *background or context*
   in which the subject will be placed. Try placing your subject in a variety
   of backgrounds. For example, a studio with a white background, outdoors, or
   indoor environments.

3. **Style:** Finally, add the style of image you want. *Styles* can be general
   (painting, photograph, sketches) or very specific (pastel painting, charcoal
   drawing, isometric 3D). You can also combine styles.

After you write a first version of your prompt, refine your prompt by adding
more details until you get to the image that you want. Iteration is important.
Start by establishing your core idea, and then refine and expand upon that core
idea until the generated image is close to your vision.

|---|---|---|
| ![photorealistic sample image 1](https://ai.google.dev/static/gemini-api/docs/images/imagen/0_prompt-writing-basics_park_short.png) Prompt: A park in the spring next to a lake | ![photorealistic sample image 2](https://ai.google.dev/static/gemini-api/docs/images/imagen/0_prompt-writing-basics_park_medium.png) Prompt: A park in the spring next to a lake, **the sun sets across the lake, golden hour** | ![photorealistic sample image 3](https://ai.google.dev/static/gemini-api/docs/images/imagen/0_prompt-writing-basics_park_long.png) Prompt: A park in the spring next to a lake, ***the sun sets across the lake, golden hour, red wildflowers*** |

Imagen models can transform your ideas into detailed images, whether
your prompts are short or long and detailed. Refine your vision
through iterative prompting, adding details until you achieve the perfect
result.

|---|---|
| Short prompts let you generate an image quickly. ![Imagen 3 short prompt example](https://ai.google.dev/static/gemini-api/docs/images/imagen/imagen3_short-prompt.png) Prompt: close-up photo of a woman in her 20s, street photography, movie still, muted orange warm tones | Longer prompts let you add specific details and build your image. ![Imagen 3 long prompt example](https://ai.google.dev/static/gemini-api/docs/images/imagen/imagen3_long-prompt.png) Prompt: captivating photo of a woman in her 20s utilizing a street photography style. The image should look like a movie still with muted orange warm tones. |

Additional advice for Imagen prompt writing:

- **Use descriptive language**: Employ detailed adjectives and adverbs to paint a clear picture for Imagen.
- **Provide context**: If necessary, include background information to aid the AI's understanding.
- **Reference specific artists or styles**: If you have a particular aesthetic in mind, referencing specific artists or art movements can be helpful.
- **Use prompt engineering tools**: Consider exploring prompt engineering tools or resources to help you refine your prompts and achieve optimal results.
- **Enhancing the facial details in your personal and group images**: Specify facial details as a focus of the photo (for example, use the word "portrait" in the prompt).

### Generate text in images

Imagen models can add text into images, opening up more creative image generation
possibilities. Use the following guidance to get the most out of this feature:

- **Iterate with confidence**: You might have to regenerate images until you achieve the look you want. Imagen's text integration is still evolving, and sometimes multiple attempts yield the best results.
- **Keep it short**: Limit text to 25 characters or less for optimal generation.
- **Multiple phrases**: Experiment with two or three distinct phrases to
  provide additional information. Avoid exceeding three phrases for cleaner
  compositions.

  ![Imagen 3 generate text example](https://ai.google.dev/static/gemini-api/docs/images/imagen/imagen3_generate-text.png) Prompt: A poster with the text "Summerland" in bold font as a title, underneath this text is the slogan "Summer never felt so good"
- **Guide Placement**: While Imagen can attempt to position text
  as directed, expect occasional variations. This feature is continually
  improving.

- **Inspire font style**: Specify a general font style to subtly influence
  Imagen's choices. Don't rely on precise font replication, but expect
  creative interpretations.

- **Font size** : Specify a font size or a general indication of size (for
  example, *small* , *medium* , *large*) to influence the font size generation.

### Prompt parameterization

To better control output results, you might find it helpful to parameterize the
inputs into Imagen. For example, suppose you
want your customers to be able to generate logos for their business, and you
want to make sure logos are always generated on a solid color background. You
also want to limit the options that the client can select from a menu.

In this example, you can create a parameterized prompt similar to the
following:  

```
A {logo_style} logo for a {company_area} company on a solid color background. Include the text {company_name}.
```

In your custom user interface, the customer can input the parameters using
a menu, and their chosen value populates the prompt Imagen receives.

For example:

1. Prompt: `A`<var translate="no">minimalist</var>` logo for a `<var translate="no">health care</var>` company on a solid color background. Include the text `<var translate="no">Journey</var>`.`

   ![Imagen 3 prompt parameterization example 1](https://ai.google.dev/static/gemini-api/docs/images/imagen/imagen3_prompt-param_healthcare.png)
2. Prompt: `A`<var translate="no">modern</var>` logo for a `<var translate="no">software</var>` company on a solid color background. Include the text `<var translate="no">Silo</var>`.`

   ![Imagen 3 prompt parameterization example 2](https://ai.google.dev/static/gemini-api/docs/images/imagen/imagen3_prompt-param_software.png)
3. Prompt: `A`<var translate="no">traditional</var>` logo for a `<var translate="no">baking</var>` company on a solid color background. Include the text `<var translate="no">Seed</var>`.`

   ![Imagen 3 prompt parameterization example 3](https://ai.google.dev/static/gemini-api/docs/images/imagen/imagen3_prompt-param_baking.png)

### Advanced prompt writing techniques

Use the following examples to create more specific prompts based on attributes
like photography descriptors, shapes and materials, historical art
movements, and image quality modifiers.

#### Photography

- Prompt includes: *"A photo of..."*

To use this style, start with using keywords that clearly tell
Imagen that you're looking for a photograph. Start your prompts with
*"A photo of. . ."*. For example:

|---|---|---|
| ![photorealistic sample image 1](https://ai.google.dev/static/gemini-api/docs/images/imagen/1_style-photography_coffee-beans.png) Prompt: **A photo of** coffee beans in a kitchen on a wooden surface | ![photorealistic sample image 2](https://ai.google.dev/static/gemini-api/docs/images/imagen/1_style-photography_chocolate-bar.png) Prompt: **A photo of** a chocolate bar on a kitchen counter | ![photorealistic sample image 3](https://ai.google.dev/static/gemini-api/docs/images/imagen/1_style-photography_modern-building.png) Prompt: **A photo of** a modern building with water in the background |

^Image source: Each image was generated using its corresponding text prompt with the Imagen 3 model.^

##### Photography modifiers

In the following examples, you can see several photography-specific modifiers
and parameters. You can combine multiple modifiers for more precise control.

1. **Camera Proximity** - *Close up, taken from far away*

   |---|---|
   | ![close up camera sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/3_camera-proximity_close-up.png) Prompt: A **close-up** photo of coffee beans | ![zoomed out camera sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/3_camera-proximity_zoomed-out.png) Prompt: A **zoomed out** photo of a small bag of coffee beans in a messy kitchen |

   <br />

2. **Camera Position** - *aerial, from below*

   |---|---|
   | ![aerial photo sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/4_camera-position_aerial-photo.png) Prompt: **aerial photo** of urban city with skyscrapers | ![a view from underneath sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/4_camera-position_from-below.png) Prompt: A photo of a forest canopy with blue skies **from below** |

3. **Lighting** - *natural, dramatic, warm, cold*

   |---|---|
   | ![natural lighting sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/5_lighting_natural-lighting.png) Prompt: studio photo of a modern arm chair, **natural lighting** | ![dramatic lighting sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/5_lighting_dramatic-lighting.png) Prompt: studio photo of a modern arm chair, **dramatic lighting** |

4. **Camera Settings** *- motion blur, soft focus, bokeh, portrait*

   |---|---|
   | ![motion blur sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/6_camera-settings_motion-blur.png) Prompt: photo of a city with skyscrapers from the inside of a car with **motion blur** | ![soft focus sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/6_camera-settings_soft-focus.png) Prompt: **soft focus** photograph of a bridge in an urban city at night |

5. **Lens types** - *35mm, 50mm, fisheye, wide angle, macro*

   |---|---|
   | ![macro lens sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/7_lens-types_macro-lens.png) Prompt: photo of a leaf, **macro lens** | ![fisheye lens sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/7_lens-types_fisheye-lens.png) Prompt: street photography, new york city, **fisheye lens** |

6. **Film types** - *black and white, polaroid*

   |---|---|
   | ![polaroid photo sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/8_film-types_polaroid-portrait.png) Prompt: a **polaroid portrait** of a dog wearing sunglasses | ![black and white photo sample image](https://ai.google.dev/static/gemini-api/docs/images/imagen/8_film-types_bw-photo.png) Prompt: **black and white photo** of a dog wearing sunglasses |

^Image source: Each image was generated using its corresponding text prompt with the Imagen 3 model.^

### Illustration and art

- Prompt includes: *"A <var translate="no">painting</var> of..."* , *"A <var translate="no">sketch</var> of..."*

Art styles vary from monochrome styles like pencil sketches, to hyper-realistic
digital art. For example, the following images use the same prompt with
different styles:

*"An <var translate="no">[art style or creation technique]</var> of an angular
sporty electric sedan with skyscrapers in the background"*

|---|---|---|
| ![art sample images](https://ai.google.dev/static/gemini-api/docs/images/imagen/2_style-illustration1A.png) Prompt: A **technical pencil drawing** of an angular... | ![art sample images](https://ai.google.dev/static/gemini-api/docs/images/imagen/2_style-illustration1B.png) Prompt: A **charcoal drawing** of an angular... | ![art sample images](https://ai.google.dev/static/gemini-api/docs/images/imagen/2_style-illustration1C.png) Prompt: A **color pencil drawing** of an angular... |

|---|---|---|
| ![art sample images](https://ai.google.dev/static/gemini-api/docs/images/imagen/2_style-illustration2E.png) Prompt: A **pastel painting** of an angular... | ![art sample images](https://ai.google.dev/static/gemini-api/docs/images/imagen/2_style-illustration2F.png) Prompt: A **digital art** of an angular... | ![art sample images](https://ai.google.dev/static/gemini-api/docs/images/imagen/2_style-illustration2G.png) Prompt: An **art deco (poster)** of an angular... |

^Image source: Each image was generated using its corresponding text prompt with the Imagen 2 model.^

##### Shapes and materials

- Prompt includes: *"...made of..."* , *"...in the shape of..."*

One of the strengths of this technology is that you can create imagery that
is otherwise difficult or impossible. For example, you can recreate
your company logo in different materials and textures.

|---|---|---|
| ![shapes and materials example image 1](https://ai.google.dev/static/gemini-api/docs/images/imagen/9_shapes-materials_duffel.png) Prompt: a duffle bag **made of** cheese | ![shapes and materials example image 2](https://ai.google.dev/static/gemini-api/docs/images/imagen/9_shapes-materials_bird.png) Prompt: neon tubes **in the shape** of a bird | ![shapes and materials example image 3](https://ai.google.dev/static/gemini-api/docs/images/imagen/9_shapes-materials_paper.png) Prompt: an armchair **made of paper**, studio photo, origami style |

^Image source: Each image was generated using its corresponding text prompt with the Imagen 3 model.^

#### Historical art references

- Prompt includes: *"...in the style of..."*

Certain styles have become iconic over the years. The following are some ideas
of historical painting or art styles that you can try.

*"generate an image in the style of <var translate="no">[art period or movement] </var>: a wind farm"*

|---|---|---|
| ![impressionism example image](https://ai.google.dev/static/gemini-api/docs/images/imagen/10_historical-ref1_impressionism.png) Prompt: generate an image **in the style of *an impressionist painting***: a wind farm | ![renaissance example image](https://ai.google.dev/static/gemini-api/docs/images/imagen/10_historical-ref1_renaissance.png) Prompt: generate an image **in the style of *a renaissance painting***: a wind farm | ![pop art example image](https://ai.google.dev/static/gemini-api/docs/images/imagen/10_historical-ref1_pop-art.png) Prompt: generate an image **in the style of *pop art***: a wind farm |

^Image source: Each image was generated using its corresponding text prompt with the Imagen 3 model.^

#### Image quality modifiers

Certain keywords can let the model know that you're looking for a high-quality
asset. Examples of quality modifiers include the following:

- **General Modifiers** - *high-quality, beautiful, stylized*
- **Photos** - *4K, HDR, Studio Photo*
- **Art, Illustration** - *by a professional, detailed*

The following are a few examples of prompts without quality modifiers and
the same prompt with quality modifiers.

|---|---|
| ![corn example image without modifiers](https://ai.google.dev/static/gemini-api/docs/images/imagen/11_quality-modifier2_no-mods.png) Prompt (no quality modifiers): a photo of a corn stalk | ![corn example image with modifiers](https://ai.google.dev/static/gemini-api/docs/images/imagen/11_quality-modifier2_4k-hdr.png) Prompt (with quality modifiers): **4k HDR beautiful** photo of a corn stalk **taken by a professional photographer** |

^Image source: Each image was generated using its corresponding text prompt with the Imagen 3 model.^

#### Aspect ratios

Imagen image generation lets you set five distinct image aspect
ratios.

1. **Square** (1:1, default) - A standard square photo. Common uses for this aspect ratio include social media posts.
2. **Fullscreen** (4:3) - This aspect ratio is commonly used in media or film.
   It is also the dimensions of most old (non-widescreen) TVs and medium format
   cameras. It captures more of the scene horizontally (compared to 1:1),
   making it a preferred aspect ratio for photography.

   |---|---|
   | ![aspect ratio example](https://ai.google.dev/static/gemini-api/docs/images/imagen/aspect-ratios_4-3_piano.png) Prompt: close up of a musician's fingers playing the piano, black and white film, vintage (4:3 aspect ratio) | ![aspect ratio example](https://ai.google.dev/static/gemini-api/docs/images/imagen/aspect-ratios_4-3_fries.png) Prompt: A professional studio photo of french fries for a high end restaurant, in the style of a food magazine (4:3 aspect ratio) |

3. **Portrait full screen** (3:4) - This is the fullscreen aspect ratio rotated
   90 degrees. This lets to capture more of the scene vertically compared to
   the 1:1 aspect ratio.

   |---|---|
   | ![aspect ratio example](https://ai.google.dev/static/gemini-api/docs/images/imagen/aspect-ratios_3-4_hiking.png) Prompt: a woman hiking, close of her boots reflected in a puddle, large mountains in the background, in the style of an advertisement, dramatic angles (3:4 aspect ratio) | ![aspect ratio example](https://ai.google.dev/static/gemini-api/docs/images/imagen/aspect-ratios_3-4_valley.png) Prompt: aerial shot of a river flowing up a mystical valley (3:4 aspect ratio) |

4. **Widescreen** (16:9) - This ratio has replaced 4:3 and is now the most
   common aspect ratio for TVs, monitors, and mobile phone screens (landscape).
   Use this aspect ratio when you want to capture more of the background (for
   example, scenic landscapes).

   ![aspect ratio example](https://ai.google.dev/static/gemini-api/docs/images/imagen/aspect-ratios_16-9_man.png) Prompt: a man wearing all white clothing sitting on the beach, close up, golden hour lighting (16:9 aspect ratio)
5. **Portrait** (9:16) - This ratio is widescreen but rotated. This a
   relatively new aspect ratio that has been popularized by short form video
   apps (for example, YouTube shorts). Use this for tall objects with strong
   vertical orientations such as buildings, trees, waterfalls, or other similar
   objects.

   ![aspect ratio example](https://ai.google.dev/static/gemini-api/docs/images/imagen/aspect-ratios_9-16_skyscraper.png) Prompt: a digital render of a massive skyscraper, modern, grand, epic with a beautiful sunset in the background (9:16 aspect ratio)

#### Photorealistic images

Different versions of the image generation
model might offer a mix of artistic and photorealistic output. Use the following
wording in prompts to generate more photorealistic output, based on the subject
you want to generate.
| **Note:** Take these keywords as general guidance when you try to create photorealistic images. They aren't required to achieve your goal.

| Use case | Lens type | Focal lengths | Additional details |
|---|---|---|---|
| People (portraits) | Prime, zoom | 24-35mm | black and white film, Film noir, Depth of field, duotone (mention two colors) |
| Food, insects, plants (objects, still life) | Macro | 60-105mm | High detail, precise focusing, controlled lighting |
| Sports, wildlife (motion) | Telephoto zoom | 100-400mm | Fast shutter speed, Action or movement tracking |
| Astronomical, landscape (wide-angle) | Wide-angle | 10-24mm | Long exposure times, sharp focus, long exposure, smooth water or clouds |

##### Portraits

| Use case | Lens type | Focal lengths | Additional details |
|---|---|---|---|
| People (portraits) | Prime, zoom | 24-35mm | black and white film, Film noir, Depth of field, duotone (mention two colors) |

Using several keywords from the table, Imagen can generate the following
portraits:

|---|---|---|---|
| ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_blue-gray1.png) | ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_blue-gray2.png) | ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_blue-gray3.png) | ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_blue-gray4.png) |

Prompt: *A woman, 35mm portrait, blue and grey duotones*

Model: `imagen-3.0-generate-002`

|---|---|---|---|
| ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_film-noir1.png) | ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_film-noir2.png) | ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_film-noir3.png) | ![portrait photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/portrait_film-noir4.png) |

Prompt: *A woman, 35mm portrait, film noir*

Model: `imagen-3.0-generate-002`

##### Objects

| Use case | Lens type | Focal lengths | Additional details |
|---|---|---|---|
| Food, insects, plants (objects, still life) | Macro | 60-105mm | High detail, precise focusing, controlled lighting |

Using several keywords from the table, Imagen can
generate the following object images:

|---|---|---|---|
| ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_leaf1.png) | ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_leaf2.png) | ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_leaf3.png) | ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_leaf4.png) |

Prompt: *leaf of a prayer plant, macro lens, 60mm*

Model: `imagen-3.0-generate-002`

|---|---|---|---|
| ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_pasta1.png) | ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_pasta2.png) | ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_pasta3.png) | ![object photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/object_pasta4.png) |

Prompt: *a plate of pasta, 100mm Macro lens*

Model: `imagen-3.0-generate-002`

##### Motion

| Use case | Lens type | Focal lengths | Additional details |
|---|---|---|---|
| Sports, wildlife (motion) | Telephoto zoom | 100-400mm | Fast shutter speed, Action or movement tracking |

Using several keywords from the table, Imagen can
generate the following motion images:

|---|---|---|---|
| ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_football1.png) | ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_football2.png) | ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_football3.png) | ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_football4.png) |

Prompt: *a winning touchdown, fast shutter speed, movement tracking*

Model: `imagen-3.0-generate-002`

|---|---|---|---|
| ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_deer1.png) | ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_deer2.png) | ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_deer3.png) | ![motion photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/motion_deer4.png) |

Prompt: *A deer running in the forest, fast shutter speed, movement tracking*

Model: `imagen-3.0-generate-002`

##### Wide-angle

| Use case | Lens type | Focal lengths | Additional details |
|---|---|---|---|
| Astronomical, landscape (wide-angle) | Wide-angle | 10-24mm | Long exposure times, sharp focus, long exposure, smooth water or clouds |

Using several keywords from the table, Imagen can
generate the following wide-angle images:

|---|---|---|---|
| ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_mountain1.png) | ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_mountain2.png) | ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_mountain3.png) | ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_mountain4.png) |

Prompt: *an expansive mountain range, landscape wide angle 10mm*

Model: `imagen-3.0-generate-002`

|---|---|---|---|
| ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_astro1.png) | ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_astro2.png) | ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_astro3.png) | ![wide-angle photography example](https://ai.google.dev/static/gemini-api/docs/images/imagen/wide-angle_astro4.png) |

Prompt: *a photo of the moon, astro photography, wide angle 10mm*

Model: `imagen-3.0-generate-002`

## Model versions

### Imagen 4

| Property | Description |
|---|---|
| id_cardModel code | **Gemini API** `imagen-4.0-generate-001` `imagen-4.0-ultra-generate-001` `imagen-4.0-fast-generate-001` |
| saveSupported data types | **Input** Text **Output** Images |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** 480 tokens (text) **Output images** 1 to 4 (Ultra/Standard/Fast) |
| calendar_monthLatest update | June 2025 |

### Imagen 3

| Property | Description |
|---|---|
| id_cardModel code | **Gemini API** `imagen-3.0-generate-002` |
| saveSupported data types | **Input** Text **Output** Images |
| token_autoToken limits^[\[\*\]](https://ai.google.dev/gemini-api/docs/tokens)^ | **Input token limit** N/A **Output images** Up to 4 |
| calendar_monthLatest update | February 2025 |

# Veo Models

<br />

[Veo 3.1](https://deepmind.google/models/veo/) is Google's state-of-the-art
model for generating high-fidelity, 8-second 720p, 1080p or 4k videos featuring
stunning realism and natively generated audio. You can access
this model programmatically using the Gemini API. To learn more about the
available Veo model variants, see the [Model Versions](https://ai.google.dev/gemini-api/docs/video#model-versions) section.

Veo 3.1 excels at a wide range of visual and cinematic styles and introduces
several new capabilities:

- **Portrait videos** : Choose between landscape (`16:9`) and portrait (`9:16`) videos.
- **Video extension**: Extend videos that were previously generated using Veo.
- **Frame-specific generation**: Generate a video by specifying the first and/or last frames.
- **Image-based direction**: Use up to three reference images to guide the content of your generated video.

For more information about writing effective text prompts for video generation,
see the [Veo prompt guide](https://ai.google.dev/gemini-api/docs/video#prompt-guide)

## Text to video generation

Choose an example to see how to generate a video with dialogue, cinematic
realism, or creative animation:

Dialogue \& Sound Effects Cinematic Realism Creative Animation  

### Python

    import time
    from google import genai
    from google.genai import types

    client = genai.Client()

    prompt = """A close up of two people staring at a cryptic drawing on a wall, torchlight flickering.
    A man murmurs, 'This must be it. That's the secret code.' The woman looks at him and whispering excitedly, 'What did you find?'"""

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the generated video.
    generated_video = operation.response.generated_videos[0]
    client.files.download(file=generated_video.video)
    generated_video.video.save("dialogue_example.mp4")
    print("Generated video saved to dialogue_example.mp4")

### JavaScript

    import { GoogleGenAI } from "@google/genai";

    const ai = new GoogleGenAI({});

    const prompt = `A close up of two people staring at a cryptic drawing on a wall, torchlight flickering.
    A man murmurs, 'This must be it. That's the secret code.' The woman looks at him and whispering excitedly, 'What did you find?'`;

    let operation = await ai.models.generateVideos({
        model: "veo-3.1-generate-preview",
        prompt: prompt,
    });

    // Poll the operation status until the video is ready.
    while (!operation.done) {
        console.log("Waiting for video generation to complete...")
        await new Promise((resolve) => setTimeout(resolve, 10000));
        operation = await ai.operations.getVideosOperation({
            operation: operation,
        });
    }

    // Download the generated video.
    ai.files.download({
        file: operation.response.generatedVideos[0].video,
        downloadPath: "dialogue_example.mp4",
    });
    console.log(`Generated video saved to dialogue_example.mp4`);

### Go

    package main

    import (
        "context"
        "log"
        "os"
        "time"

        "google.golang.org/genai"
    )

    func main() {
        ctx := context.Background()
        client, err := genai.NewClient(ctx, nil)
        if err != nil {
            log.Fatal(err)
        }

        prompt := `A close up of two people staring at a cryptic drawing on a wall, torchlight flickering.
        A man murmurs, 'This must be it. That's the secret code.' The woman looks at him and whispering excitedly, 'What did you find?'`

        operation, _ := client.Models.GenerateVideos(
            ctx,
            "veo-3.1-generate-preview",
            prompt,
            nil,
            nil,
        )

        // Poll the operation status until the video is ready.
        for !operation.Done {
        log.Println("Waiting for video generation to complete...")
            time.Sleep(10 * time.Second)
            operation, _ = client.Operations.GetVideosOperation(ctx, operation, nil)
        }

        // Download the generated video.
        video := operation.Response.GeneratedVideos[0]
        client.Files.Download(ctx, video.Video, nil)
        fname := "dialogue_example.mp4"
        _ = os.WriteFile(fname, video.Video.VideoBytes, 0644)
        log.Printf("Generated video saved to %s\n", fname)
    }

### REST

    # Note: This script uses jq to parse the JSON response.
    # GEMINI API Base URL
    BASE_URL="https://generativelanguage.googleapis.com/v1beta"

    # Send request to generate video and capture the operation name into a variable.
    operation_name=$(curl -s "${BASE_URL}/models/veo-3.1-generate-preview:predictLongRunning" \
      -H "x-goog-api-key: $GEMINI_API_KEY" \
      -H "Content-Type: application/json" \
      -X "POST" \
      -d '{
        "instances": [{
            "prompt": "A close up of two people staring at a cryptic drawing on a wall, torchlight flickering. A man murmurs, \"This must be it. That'\''s the secret code.\" The woman looks at him and whispering excitedly, \"What did you find?\""
          }
        ]
      }' | jq -r .name)

    # Poll the operation status until the video is ready
    while true; do
      # Get the full JSON status and store it in a variable.
      status_response=$(curl -s -H "x-goog-api-key: $GEMINI_API_KEY" "${BASE_URL}/${operation_name}")

      # Check the "done" field from the JSON stored in the variable.
      is_done=$(echo "${status_response}" | jq .done)

      if [ "${is_done}" = "true" ]; then
        # Extract the download URI from the final response.
        video_uri=$(echo "${status_response}" | jq -r '.response.generateVideoResponse.generatedSamples[0].video.uri')
        echo "Downloading video from: ${video_uri}"

        # Download the video using the URI and API key and follow redirects.
        curl -L -o dialogue_example.mp4 -H "x-goog-api-key: $GEMINI_API_KEY" "${video_uri}"
        break
      fi
      # Wait for 5 seconds before checking again.
      sleep 10
    done

### Control the aspect ratio

Veo 3.1 lets you create landscape (`16:9`, the default setting) or portrait
(`9:16`) videos. You can tell the model which one you want using the
`aspect_ratio` parameter:  

### Python

    import time
    from google import genai
    from google.genai import types

    client = genai.Client()

    prompt = """A montage of pizza making: a chef tossing and flattening the floury dough, ladling rich red tomato sauce in a spiral, sprinkling mozzarella cheese and pepperoni, and a final shot of the bubbling golden-brown pizza, upbeat electronic music with a rhythmical beat is playing, high energy professional video."""

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
        config=types.GenerateVideosConfig(
          aspect_ratio="9:16",
        ),
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the generated video.
    generated_video = operation.response.generated_videos[0]
    client.files.download(file=generated_video.video)
    generated_video.video.save("pizza_making.mp4")
    print("Generated video saved to pizza_making.mp4")

### JavaScript

    import { GoogleGenAI } from "@google/genai";

    const ai = new GoogleGenAI({});

    const prompt = `A montage of pizza making: a chef tossing and flattening the floury dough, ladling rich red tomato sauce in a spiral, sprinkling mozzarella cheese and pepperoni, and a final shot of the bubbling golden-brown pizza, upbeat electronic music with a rhythmical beat is playing, high energy professional video.`;

    let operation = await ai.models.generateVideos({
        model: "veo-3.1-generate-preview",
        prompt: prompt,
        config: {
          aspectRatio: "9:16",
        },
    });

    // Poll the operation status until the video is ready.
    while (!operation.done) {
        console.log("Waiting for video generation to complete...")
        await new Promise((resolve) => setTimeout(resolve, 10000));
        operation = await ai.operations.getVideosOperation({
            operation: operation,
        });
    }

    // Download the generated video.
    ai.files.download({
        file: operation.response.generatedVideos[0].video,
        downloadPath: "pizza_making.mp4",
    });
    console.log(`Generated video saved to pizza_making.mp4`);

### Go

    package main

    import (
        "context"
        "log"
        "os"
        "time"

        "google.golang.org/genai"
    )

    func main() {
        ctx := context.Background()
        client, err := genai.NewClient(ctx, nil)
        if err != nil {
            log.Fatal(err)
        }

        prompt := `A montage of pizza making: a chef tossing and flattening the floury dough, ladling rich red tomato sauce in a spiral, sprinkling mozzarella cheese and pepperoni, and a final shot of the bubbling golden-brown pizza, upbeat electronic music with a rhythmical beat is playing, high energy professional video.`

      videoConfig := &genai.GenerateVideosConfig{
          AspectRatio: "9:16",
      }

        operation, _ := client.Models.GenerateVideos(
            ctx,
            "veo-3.1-generate-preview",
            prompt,
            nil,
            videoConfig,
        )

        // Poll the operation status until the video is ready.
        for !operation.Done {
        log.Println("Waiting for video generation to complete...")
            time.Sleep(10 * time.Second)
            operation, _ = client.Operations.GetVideosOperation(ctx, operation, nil)
        }

        // Download the generated video.
        video := operation.Response.GeneratedVideos[0]
        client.Files.Download(ctx, video.Video, nil)
        fname := "pizza_making.mp4"
        _ = os.WriteFile(fname, video.Video.VideoBytes, 0644)
        log.Printf("Generated video saved to %s\n", fname)
    }

### REST

    # Note: This script uses jq to parse the JSON response.
    # GEMINI API Base URL
    BASE_URL="https://generativelanguage.googleapis.com/v1beta"

    # Send request to generate video and capture the operation name into a variable.
    operation_name=$(curl -s "${BASE_URL}/models/veo-3.1-generate-preview:predictLongRunning" \
      -H "x-goog-api-key: $GEMINI_API_KEY" \
      -H "Content-Type: application/json" \
      -X "POST" \
      -d '{
        "instances": [{
            "prompt": "A montage of pizza making: a chef tossing and flattening the floury dough, ladling rich red tomato sauce in a spiral, sprinkling mozzarella cheese and pepperoni, and a final shot of the bubbling golden-brown pizza, upbeat electronic music with a rhythmical beat is playing, high energy professional video."
          }
        ],
        "parameters": {
          "aspectRatio": "9:16"
        }
      }' | jq -r .name)

    # Poll the operation status until the video is ready
    while true; do
      # Get the full JSON status and store it in a variable.
      status_response=$(curl -s -H "x-goog-api-key: $GEMINI_API_KEY" "${BASE_URL}/${operation_name}")

      # Check the "done" field from the JSON stored in the variable.
      is_done=$(echo "${status_response}" | jq .done)

      if [ "${is_done}" = "true" ]; then
        # Extract the download URI from the final response.
        video_uri=$(echo "${status_response}" | jq -r '.response.generateVideoResponse.generatedSamples[0].video.uri')
        echo "Downloading video from: ${video_uri}"

        # Download the video using the URI and API key and follow redirects.
        curl -L -o pizza_making.mp4 -H "x-goog-api-key: $GEMINI_API_KEY" "${video_uri}"
        break
      fi
      # Wait for 5 seconds before checking again.
      sleep 10
    done

### Control the resolution

Veo 3.1 can also directly generate 720p, 1080p or 4k videos.

Note that the higher the resolution, the higher the latency will be. 4k videos
are also more pricey (cf. [pricing](https://ai.google.dev/gemini-api/docs/pricing#veo-3.1)).

[Video extension](https://ai.google.dev/gemini-api/docs/video#extending_veo_videos) is also limited to 720p videos.  

### Python

    import time
    from google import genai
    from google.genai import types

    client = genai.Client()

    prompt = """A stunning drone view of the Grand Canyon during a flamboyant sunset that highlights the canyon's colors. The drone slowly flies towards the sun then accelerates, dives and flies inside the canyon."""

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
        config=types.GenerateVideosConfig(
          resolution="4k",
        ),
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the generated video.
    generated_video = operation.response.generated_videos[0]
    client.files.download(file=generated_video.video)
    generated_video.video.save("4k_grand_canyon.mp4")
    print("Generated video saved to 4k_grand_canyon.mp4")

### JavaScript

    import { GoogleGenAI } from "@google/genai";

    const ai = new GoogleGenAI({});

    const prompt = `A stunning drone view of the Grand Canyon during a flamboyant sunset that highlights the canyon's colors. The drone slowly flies towards the sun then accelerates, dives and flies inside the canyon.`;

    let operation = await ai.models.generateVideos({
        model: "veo-3.1-generate-preview",
        prompt: prompt,
        config: {
          resolution: "4k",
        },
    });

    // Poll the operation status until the video is ready.
    while (!operation.done) {
        console.log("Waiting for video generation to complete...")
        await new Promise((resolve) => setTimeout(resolve, 10000));
        operation = await ai.operations.getVideosOperation({
            operation: operation,
        });
    }

    // Download the generated video.
    ai.files.download({
        file: operation.response.generatedVideos[0].video,
        downloadPath: "4k_grand_canyon.mp4",
    });
    console.log(`Generated video saved to 4k_grand_canyon.mp4`);

### Go

    package main

    import (
        "context"
        "log"
        "os"
        "time"

        "google.golang.org/genai"
    )

    func main() {
        ctx := context.Background()
        client, err := genai.NewClient(ctx, nil)
        if err != nil {
            log.Fatal(err)
        }

        prompt := `A stunning drone view of the Grand Canyon during a flamboyant sunset that highlights the canyon's colors. The drone slowly flies towards the sun then accelerates, dives and flies inside the canyon.`

      videoConfig := &genai.GenerateVideosConfig{
          Resolution: "4k",
      }

        operation, _ := client.Models.GenerateVideos(
            ctx,
            "veo-3.1-generate-preview",
            prompt,
            nil,
            videoConfig,
        )

        // Poll the operation status until the video is ready.
        for !operation.Done {
        log.Println("Waiting for video generation to complete...")
            time.Sleep(10 * time.Second)
            operation, _ = client.Operations.GetVideosOperation(ctx, operation, nil)
        }

        // Download the generated video.
        video := operation.Response.GeneratedVideos[0]
        client.Files.Download(ctx, video.Video, nil)
        fname := "4k_grand_canyon.mp4"
        _ = os.WriteFile(fname, video.Video.VideoBytes, 0644)
        log.Printf("Generated video saved to %s\n", fname)
    }

### REST

    # Note: This script uses jq to parse the JSON response.
    # GEMINI API Base URL
    BASE_URL="https://generativelanguage.googleapis.com/v1beta"

    # Send request to generate video and capture the operation name into a variable.
    operation_name=$(curl -s "${BASE_URL}/models/veo-3.1-generate-preview:predictLongRunning" \
      -H "x-goog-api-key: $GEMINI_API_KEY" \
      -H "Content-Type: application/json" \
      -X "POST" \
      -d '{
        "instances": [{
            "prompt": "A stunning drone view of the Grand Canyon during a flamboyant sunset that highlights the canyon'\''s colors. The drone slowly flies towards the sun then accelerates, dives and flies inside the canyon."
          }
        ],
        "parameters": {
          "resolution": "4k"
        }
      }' | jq -r .name)

    # Poll the operation status until the video is ready
    while true; do
      # Get the full JSON status and store it in a variable.
      status_response=$(curl -s -H "x-goog-api-key: $GEMINI_API_KEY" "${BASE_URL}/${operation_name}")

      # Check the "done" field from the JSON stored in the variable.
      is_done=$(echo "${status_response}" | jq .done)

      if [ "${is_done}" = "true" ]; then
        # Extract the download URI from the final response.
        video_uri=$(echo "${status_response}" | jq -r '.response.generateVideoResponse.generatedSamples[0].video.uri')
        echo "Downloading video from: ${video_uri}"

        # Download the video using the URI and API key and follow redirects.
        curl -L -o 4k_grand_canyon.mp4 -H "x-goog-api-key: $GEMINI_API_KEY" "${video_uri}"
        break
      fi
      # Wait for 5 seconds before checking again.
      sleep 10
    done

## Image to video generation

The following code demonstrates generating an image using
[Gemini 2.5 Flash Image aka Nano Banana](https://ai.google.dev/gemini-api/docs/image-generation),
then using that image as the
starting frame for generating a video with Veo 3.1.  

### Python

    import time
    from google import genai

    client = genai.Client()

    prompt = "Panning wide shot of a calico kitten sleeping in the sunshine"

    # Step 1: Generate an image with Nano Banana.
    image = client.models.generate_content(
        model="gemini-2.5-flash-image",
        contents=prompt,
        config={"response_modalities":['IMAGE']}
    )

    # Step 2: Generate video with Veo 3.1 using the image.
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
        image=image.parts[0].as_image(),
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the video.
    video = operation.response.generated_videos[0]
    client.files.download(file=video.video)
    video.video.save("veo3_with_image_input.mp4")
    print("Generated video saved to veo3_with_image_input.mp4")

### JavaScript

    import { GoogleGenAI } from "@google/genai";

    const ai = new GoogleGenAI({});

    const prompt = "Panning wide shot of a calico kitten sleeping in the sunshine";

    // Step 1: Generate an image with Nano Banana.
    const imageResponse = await ai.models.generateContent({
      model: "gemini-2.5-flash-image",
      prompt: prompt,
    });

    // Step 2: Generate video with Veo 3.1 using the image.
    let operation = await ai.models.generateVideos({
      model: "veo-3.1-generate-preview",
      prompt: prompt,
      image: {
        imageBytes: imageResponse.generatedImages[0].image.imageBytes,
        mimeType: "image/png",
      },
    });

    // Poll the operation status until the video is ready.
    while (!operation.done) {
      console.log("Waiting for video generation to complete...")
      await new Promise((resolve) => setTimeout(resolve, 10000));
      operation = await ai.operations.getVideosOperation({
        operation: operation,
      });
    }

    // Download the video.
    ai.files.download({
        file: operation.response.generatedVideos[0].video,
        downloadPath: "veo3_with_image_input.mp4",
    });
    console.log(`Generated video saved to veo3_with_image_input.mp4`);

### Go

    package main

    import (
        "context"
        "log"
        "os"
        "time"

        "google.golang.org/genai"
    )

    func main() {
        ctx := context.Background()
        client, err := genai.NewClient(ctx, nil)
        if err != nil {
            log.Fatal(err)
        }

        prompt := "Panning wide shot of a calico kitten sleeping in the sunshine"

        // Step 1: Generate an image with Nano Banana.
        imageResponse, err := client.Models.GenerateContent(
            ctx,
            "gemini-2.5-flash-image",
            prompt,
            nil, // GenerateImagesConfig
        )
        if err != nil {
            log.Fatal(err)
        }

        // Step 2: Generate video with Veo 3.1 using the image.
        operation, err := client.Models.GenerateVideos(
            ctx,
            "veo-3.1-generate-preview",
            prompt,
            imageResponse.GeneratedImages[0].Image,
            nil, // GenerateVideosConfig
        )
        if err != nil {
            log.Fatal(err)
        }

        // Poll the operation status until the video is ready.
        for !operation.Done {
            log.Println("Waiting for video generation to complete...")
            time.Sleep(10 * time.Second)
            operation, _ = client.Operations.GetVideosOperation(ctx, operation, nil)
        }

        // Download the video.
        video := operation.Response.GeneratedVideos[0]
        client.Files.Download(ctx, video.Video, nil)
        fname := "veo3_with_image_input.mp4"
        _ = os.WriteFile(fname, video.Video.VideoBytes, 0644)
        log.Printf("Generated video saved to %s\n", fname)
    }

### Using reference images

| **Note:** This feature is available for Veo 3.1 models only and is limited to the 16:9 aspect ratio.

Veo 3.1 now accepts up to 3 reference images to guide your generated video's
content. Provide images of a person, character, or product to
preserve the subject's appearance in the output video.

For example, using these three images generated with
[Nano Banana](https://ai.google.dev/gemini-api/docs/image-generation) as references with a
[well-written prompt](https://ai.google.dev/gemini-api/docs/video#use-reference-images) creates the following video:

| ```dress_image``` | ```woman_image``` | ```glasses_image``` |
|---|---|---|
| ![High-fashion flamingo dress with layers of pink and fuchsia feathers](https://storage.googleapis.com/generativeai-downloads/images/flamingo.png) | ![Beautiful woman with dark hair and warm brown eyes](https://storage.googleapis.com/generativeai-downloads/images/flamingo_woman.png) | ![Whimsical pink, heart-shaped sunglasses](https://storage.googleapis.com/generativeai-downloads/images/flamingo_glasses.png) |

### Python

    import time
    from google import genai

    client = genai.Client()

    prompt = "The video opens with a medium, eye-level shot of a beautiful woman with dark hair and warm brown eyes. She wears a magnificent, high-fashion flamingo dress with layers of pink and fuchsia feathers, complemented by whimsical pink, heart-shaped sunglasses. She walks with serene confidence through the crystal-clear, shallow turquoise water of a sun-drenched lagoon. The camera slowly pulls back to a medium-wide shot, revealing the breathtaking scene as the dress's long train glides and floats gracefully on the water's surface behind her. The cinematic, dreamlike atmosphere is enhanced by the vibrant colors of the dress against the serene, minimalist landscape, capturing a moment of pure elegance and high-fashion fantasy."

    dress_reference = types.VideoGenerationReferenceImage(
      image=dress_image, # Generated separately with Nano Banana
      reference_type="asset"
    )

    sunglasses_reference = types.VideoGenerationReferenceImage(
      image=glasses_image, # Generated separately with Nano Banana
      reference_type="asset"
    )

    woman_reference = types.VideoGenerationReferenceImage(
      image=woman_image, # Generated separately with Nano Banana
      reference_type="asset"
    )

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
        config=types.GenerateVideosConfig(
          reference_images=[dress_reference, glasses_reference, woman_reference],
        ),
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the video.
    video = operation.response.generated_videos[0]
    client.files.download(file=video.video)
    video.video.save("veo3.1_with_reference_images.mp4")
    print("Generated video saved to veo3.1_with_reference_images.mp4")

### Using first and last frames

| **Note:** This feature is available for Veo 3.1 models only

Veo 3.1 lets you create videos using interpolation, or specifying the first and
last frames of the video. For information about writing effective text prompts
for video generation, see the [Veo prompt guide](https://ai.google.dev/gemini-api/docs/video#use-reference-images).  

### Python

    import time
    from google import genai

    client = genai.Client()

    prompt = "A cinematic, haunting video. A ghostly woman with long white hair and a flowing dress swings gently on a rope swing beneath a massive, gnarled tree in a foggy, moonlit clearing. The fog thickens and swirls around her, and she slowly fades away, vanishing completely. The empty swing is left swaying rhythmically on its own in the eerie silence."

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
        image=first_image, # Generated separately with Nano Banana
        config=types.GenerateVideosConfig(
          last_frame=last_image # Generated separately with Nano Banana
        ),
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the video.
    video = operation.response.generated_videos[0]
    client.files.download(file=video.video)
    video.video.save("veo3.1_with_interpolation.mp4")
    print("Generated video saved to veo3.1_with_interpolation.mp4")

| ```first_image``` | ```last_image``` | *veo3.1_with_interpolation.mp4* |
|---|---|---|
| ![A ghostly woman with long white hair and a flowing dress swings gently on a rope swing](https://storage.googleapis.com/generativeai-downloads/images/ghost_girl.png) | ![The ghostly woman vanishes from the swing](https://storage.googleapis.com/generativeai-downloads/images/empty_tree.png) | ![A cinematic, haunting video of an eerie woman disappearing from a swing in the mist](https://storage.googleapis.com/generativeai-downloads/images/creepy_swing.gif) |

## Extending Veo videos

| **Note:** This feature is available for Veo 3.1 models only

Use Veo 3.1 to extend videos that you previously generated with Veo by 7 seconds
and up to 20 times.

Input video limitations:

- Veo-generated videos only up to 141 seconds long.
- Gemini API only supports video extensions for Veo-generated videos.
- The video should come from a previous generation, like `operation.response.generated_videos[0].video`
- Videos are stored for 2 days, but if a video is referenced for extension, its 2-day storage timer resets. You can only extend videos that were generated or referenced in the last two days.
- Input videos are expected to have a certain length, aspect ratio, and dimensions:
  - Aspect ratio: 9:16 or 16:9
  - Resolution: 720p
  - Video length: 141 seconds or less

The output of the extension is a single video combining the user input video and
the generated extended video for up to 148 seconds of video.

This example takes the a Veo-generated video, shown here with
its original prompt, and extends it using the `video` parameter and a new
prompt:

| Prompt | Output: `butterfly_video` |
|---|---|
| An origami butterfly flaps its wings and flies out of the french doors into the garden. | ![Origami butterfly flaps its wings and flies out of the french doors into the garden.](https://storage.googleapis.com/generativeai-downloads/images/Butterfly_original.gif) |

### Python

    import time
    from google import genai

    client = genai.Client()

    prompt = "Track the butterfly into the garden as it lands on an orange origami flower. A fluffy white puppy runs up and gently pats the flower."

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        video=operation.response.generated_videos[0].video, # This must be a video from a previous generation
        prompt=prompt,
        config=types.GenerateVideosConfig(
            number_of_videos=1,
            resolution="720p"
        ),
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the video.
    video = operation.response.generated_videos[0]
    client.files.download(file=video.video)
    video.video.save("veo3.1_extension.mp4")
    print("Generated video saved to veo3.1_extension.mp4")

For information about writing effective text prompts for video generation, see
the [Veo prompt guide](https://ai.google.dev/gemini-api/docs/video#extend-prompt).

## Handling asynchronous operations

Video generation is a computationally intensive task. When you send a request
to the API, it starts a long-running job and immediately returns an `operation`
object. You must then poll until the video is ready, which is indicated by the
`done` status being true.

The core of this process is a polling loop, which periodically checks the job's
status.  

### Python

    import time
    from google import genai
    from google.genai import types

    client = genai.Client()

    # After starting the job, you get an operation object.
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt="A cinematic shot of a majestic lion in the savannah.",
    )

    # Alternatively, you can use operation.name to get the operation.
    operation = types.GenerateVideosOperation(name=operation.name)

    # This loop checks the job status every 10 seconds.
    while not operation.done:
        time.sleep(10)
        # Refresh the operation object to get the latest status.
        operation = client.operations.get(operation)

    # Once done, the result is in operation.response.
    # ... process and download your video ...

### JavaScript

    import { GoogleGenAI } from "@google/genai";

    const ai = new GoogleGenAI({});

    // After starting the job, you get an operation object.
    let operation = await ai.models.generateVideos({
      model: "veo-3.1-generate-preview",
      prompt: "A cinematic shot of a majestic lion in the savannah.",
    });

    // Alternatively, you can use operation.name to get the operation.
    // operation = types.GenerateVideosOperation(name=operation.name)

    // This loop checks the job status every 10 seconds.
    while (!operation.done) {
        await new Promise((resolve) => setTimeout(resolve, 1000));
        // Refresh the operation object to get the latest status.
        operation = await ai.operations.getVideosOperation({ operation });
    }

    // Once done, the result is in operation.response.
    // ... process and download your video ...

## Veo API parameters and specifications

These are the parameters you can set in your API request to control the video
generation process.

| Parameter | Description | Veo 3.1 \& Veo 3.1 Fast | Veo 3 \& Veo 3 Fast | Veo 2 |
|---|---|---|---|---|
| `prompt` | The text description for the video. Supports audio cues. | `string` | `string` | `string` |
| `negativePrompt` | Text describing what not to include in the video. | `string` | `string` | `string` |
| `image` | An initial image to animate. | `Image` object | `Image` object | `Image` object |
| `lastFrame` | The final image for an interpolation video to transition. Must be used in combination with the `image` parameter. | `Image` object | `Image` object | `Image` object |
| `referenceImages` | Up to three images to be used as style and content references. | `VideoGenerationReferenceImage` object | n/a | n/a |
| `video` | Video to be used for video extension. | `Video` object from a previous generation | n/a | n/a |
| `aspectRatio` | The video's aspect ratio. | `"16:9"` (default), `"9:16"` | `"16:9"` (default), `"9:16"` | `"16:9"` (default), `"9:16"` |
| `resolution` | The video's aspect ratio. | `"720p"` (default), `"1080p"` (only supports 8s duration), `"4k"` (only supports 8s duration) *`"720p"` only for extension* | `"720p"` (default), `"1080p"` (only supports 8s duration), `"4k"` (only supports 8s duration) *`"720p"` only for extension* | Unsupported |
| `durationSeconds` | Length of the generated video. | `"4"`, `"6"`, `"8"`. *Must be "8" when using extension, reference images or with 1080p and 4k resolutions* | `"4"`, `"6"`, `"8"`. *Must be "8" when using extension, reference images or with 1080p and 4k resolutions* | `"5"`, `"6"`, `"8"` |
| `personGeneration` | Controls the generation of people. (See [Limitations](https://ai.google.dev/gemini-api/docs/video#limitations) for region restrictions) | Text-to-video \& Extension: `"allow_all"` only Image-to-video, Interpolation, \& Reference images: `"allow_adult"` only | Text-to-video: `"allow_all"` only Image-to-video: `"allow_adult"` only | Text-to-video: `"allow_all"`, `"allow_adult"`, `"dont_allow"` Image-to-video: `"allow_adult"`, and `"dont_allow"` |

Note that the `seed` parameter is also available for Veo 3 models.
It doesn't guarantee determinism, but slightly improves it.

You can customize your video generation by setting parameters in your request.
For example you can specify `negativePrompt` to guide the model.  

### Python

    import time
    from google import genai
    from google.genai import types

    client = genai.Client()

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt="A cinematic shot of a majestic lion in the savannah.",
        config=types.GenerateVideosConfig(negative_prompt="cartoon, drawing, low quality"),
    )

    # Poll the operation status until the video is ready.
    while not operation.done:
        print("Waiting for video generation to complete...")
        time.sleep(10)
        operation = client.operations.get(operation)

    # Download the generated video.
    generated_video = operation.response.generated_videos[0]
    client.files.download(file=generated_video.video)
    generated_video.video.save("parameters_example.mp4")
    print("Generated video saved to parameters_example.mp4")

### JavaScript

    import { GoogleGenAI } from "@google/genai";

    const ai = new GoogleGenAI({});

    let operation = await ai.models.generateVideos({
      model: "veo-3.1-generate-preview",
      prompt: "A cinematic shot of a majestic lion in the savannah.",
      config: {
        aspectRatio: "16:9",
        negativePrompt: "cartoon, drawing, low quality"
      },
    });

    // Poll the operation status until the video is ready.
    while (!operation.done) {
      console.log("Waiting for video generation to complete...")
      await new Promise((resolve) => setTimeout(resolve, 10000));
      operation = await ai.operations.getVideosOperation({
        operation: operation,
      });
    }

    // Download the generated video.
    ai.files.download({
        file: operation.response.generatedVideos[0].video,
        downloadPath: "parameters_example.mp4",
    });
    console.log(`Generated video saved to parameters_example.mp4`);

### Go

    package main

    import (
        "context"
        "log"
        "os"
        "time"

        "google.golang.org/genai"
    )

    func main() {
        ctx := context.Background()
        client, err := genai.NewClient(ctx, nil)
        if err != nil {
            log.Fatal(err)
        }

        videoConfig := &genai.GenerateVideosConfig{
            AspectRatio: "16:9",
            NegativePrompt: "cartoon, drawing, low quality",
        }

        operation, _ := client.Models.GenerateVideos(
            ctx,
            "veo-3.1-generate-preview",
            "A cinematic shot of a majestic lion in the savannah.",
            nil,
            videoConfig,
        )

        // Poll the operation status until the video is ready.
        for !operation.Done {
            log.Println("Waiting for video generation to complete...")
            time.Sleep(10 * time.Second)
            operation, _ = client.Operations.GetVideosOperation(ctx, operation, nil)
        }

        // Download the generated video.
        video := operation.Response.GeneratedVideos[0]
        client.Files.Download(ctx, video.Video, nil)
        fname := "parameters_example.mp4"
        _ = os.WriteFile(fname, video.Video.VideoBytes, 0644)
        log.Printf("Generated video saved to %s\n", fname)
    }

### REST

    # Note: This script uses jq to parse the JSON response.
    # GEMINI API Base URL
    BASE_URL="https://generativelanguage.googleapis.com/v1beta"

    # Send request to generate video and capture the operation name into a variable.
    operation_name=$(curl -s "${BASE_URL}/models/veo-3.1-generate-preview:predictLongRunning" \
      -H "x-goog-api-key: $GEMINI_API_KEY" \
      -H "Content-Type: application/json" \
      -X "POST" \
      -d '{
        "instances": [{
            "prompt": "A cinematic shot of a majestic lion in the savannah."
          }
        ],
        "parameters": {
          "aspectRatio": "16:9",
          "negativePrompt": "cartoon, drawing, low quality"
        }
      }' | jq -r .name)

    # Poll the operation status until the video is ready
    while true; do
      # Get the full JSON status and store it in a variable.
      status_response=$(curl -s -H "x-goog-api-key: $GEMINI_API_KEY" "${BASE_URL}/${operation_name}")

      # Check the "done" field from the JSON stored in the variable.
      is_done=$(echo "${status_response}" | jq .done)

      if [ "${is_done}" = "true" ]; then
        # Extract the download URI from the final response.
        video_uri=$(echo "${status_response}" | jq -r '.response.generateVideoResponse.generatedSamples[0].video.uri')
        echo "Downloading video from: ${video_uri}"

        # Download the video using the URI and API key and follow redirects.
        curl -L -o parameters_example.mp4 -H "x-goog-api-key: $GEMINI_API_KEY" "${video_uri}"
        break
      fi
      # Wait for 5 seconds before checking again.
      sleep 10
    done

## Veo prompt guide

This section contains examples of videos you can create using Veo, and shows you
how to modify prompts to produce distinct results.

### Safety filters

Veo applies safety filters across Gemini to help ensure that
generated videos and uploaded photos don't contain offensive content.
Prompts that violate our [terms and guidelines](https://ai.google.dev/gemini-api/docs/usage-policies#abuse-monitoring) are blocked.

### Prompt writing basics

Good prompts are descriptive and clear. To get the most out of Veo, start with
identifying your core idea, refine your idea by adding keywords and modifiers,
and incorporate video-specific terminology into your prompts.

The following elements should be included in your prompt:

- **Subject** : The object, person, animal, or scenery that you want in your video, such as *cityscape* , *nature* , *vehicles* , or *puppies*.
- **Action** : What the subject is doing (for example, *walking* , *running* , or *turning their head*).
- **Style** : Specify creative direction using specific film style keywords, such as *sci-fi* , *horror film* , *film noir* , or animated styles like *cartoon*.
- **Camera positioning and motion** : \[Optional\] Control the camera's location and movement using terms like *aerial view* , *eye-level* , *top-down shot* , *dolly shot* , or *worms eye*.
- **Composition** : \[Optional\] How the shot is framed, such as *wide shot* , *close-up* , *single-shot* or *two-shot*.
- **Focus and lens effects** : \[Optional\] Use terms like *shallow focus* , *deep focus* , *soft focus* , *macro lens* , and *wide-angle lens* to achieve specific visual effects.
- **Ambiance** : \[Optional\] How the color and light contribute to the scene, such as *blue tones* , *night* , or *warm tones*.

#### More tips for writing prompts

- **Use descriptive language**: Use adjectives and adverbs to paint a clear picture for Veo.
- **Enhance the facial details** : Specify facial details as a focus of the photo like using the word *portrait* in the prompt.

*For more comprehensive prompting strategies, visit [Introduction to
prompt design](https://ai.google.dev/gemini-api/docs/prompting-intro).*

### Prompting for audio

With Veo 3, you can provide cues for sound effects, ambient noise, and dialogue.
The model captures the nuance of these cues to generate a synchronized
soundtrack.

- **Dialogue:** Use quotes for specific speech. (Example: "This must be the key," he murmured.)
- **Sound Effects (SFX):** Explicitly describe sounds. (Example: tires screeching loudly, engine roaring.)
- **Ambient Noise:** Describe the environment's soundscape. (Example: A faint, eerie hum resonates in the background.)

These videos demonstrate prompting Veo 3's audio generation with increasing
levels of detail.

| **Prompt** | **Generated output** |
|---|---|
| **More detail (Dialogue and ambience)** A wide shot of a misty Pacific Northwest forest. Two exhausted hikers, a man and a woman, push through ferns when the man stops abruptly, staring at a tree. Close-up: Fresh, deep claw marks are gouged into the tree's bark. Man: (Hand on his hunting knife) "That's no ordinary bear." Woman: (Voice tight with fear, scanning the woods) "Then what is it?" A rough bark, snapping twigs, footsteps on the damp earth. A lone bird chirps. | ![Two people in the woods encounter signs of a bear.](https://storage.googleapis.com/generativeai-downloads/images/Scary_Bear.gif) |
| **Less detail (Dialogue)** Paper Cut-Out Animation. New Librarian: "Where do you keep the forbidden books?" Old Curator: "We don't. They keep us." | ![Animated librarians discussing forbidden books](https://storage.googleapis.com/generativeai-downloads/images/Library.gif) |

Try out these prompts yourself to hear the audio!

[Try Veo 3](https://deepmind.google/models/veo/)

### Prompting with reference images

You can use one or more images as inputs to guide your generated videos, using
Veo's [image-to-video](https://ai.google.dev/gemini-api/docs/video#generate-from-images)
capabilities. Veo uses the input image as the initial frame. Select an image
closest to what you envision as the first scene of your video to animate
everyday objects, bring drawings and paintings to life, and add movement and
sound to nature scenes.

| **Prompt** | **Generated output** |
|---|---|
| **Input image (Generated by Nano Banana)** A hyperrealistic macro photo of tiny, miniature surfers riding ocean waves inside a rustic stone bathroom sink. A vintage brass faucet is running, creating the perpetual surf. Surreal, whimsical, bright natural lighting. | ![Tiny, miniature surfers riding ocean waves inside a rustic stone bathroom sink.](https://storage.googleapis.com/generativeai-downloads/images/Sink_Surfers.png) |
| **Output Video (Generated by Veo 3.1)** A surreal, cinematic macro video. Tiny surfers ride perpetual, rolling waves inside a stone bathroom sink. A running vintage brass faucet generates the endless surf. The camera slowly pans across the whimsical, sunlit scene as the miniature figures expertly carve the turquoise water. | ![Tiny surfers circling the waves in a bathroom sink.](https://storage.googleapis.com/generativeai-downloads/images/sink_surfers.gif) |

Veo 3.1 lets you reference images or ingredients to direct your generated
video's content. Provide up to three asset images of a single person, character,
or product. Veo preserves the subject's appearance in the output video.

| **Prompt** | **Generated output** |
|---|---|
| **Reference image (Generated by Nano Banana)** A deep sea angler fish lurks in the deep dark water, teeth bared and bait glowing. | ![A dark and glowing angler fish](https://storage.googleapis.com/generativeai-downloads/images/angler_fish.png) |
| **Reference image (Generated by Nano Banana)** A pink child's princess costume complete with a wand and tiara, on a plain product background. | ![A childs pink princess constume](https://storage.googleapis.com/generativeai-downloads/images/princess_dress.png) |
| **Output Video (Generated by Veo 3.1)** Create a silly cartoon version of the fish wearing the costume, swimming and waving the wand around. | ![An angler fish wearing a princess costume](https://storage.googleapis.com/generativeai-downloads/images/angler_princess.gif) |

Using Veo 3.1, you can also generate videos by specifying the first and last
frames of the video.

| **Prompt** | **Generated output** |
|---|---|
| **First image (Generated by Nano Banana)** A high quality photorealistic front image of a ginger cat driving a red convertible racing car on the French riviera coast. | ![A ginger cat driving a red convertible racing car](https://storage.googleapis.com/generativeai-downloads/images/ginger_race_cat.jpeg) |
| **Last image (Generated by Nano Banana)** Show what happens when the car takes off from a cliff. | ![A ginger cat driving a red convertible goes off a cliff](https://storage.googleapis.com/generativeai-downloads/images/race_cat_cliff.jpeg) |
| **Output Video (Generated by Veo 3.1)** Optional | ![A cat drives of a cliff and takes off](https://storage.googleapis.com/generativeai-downloads/images/race_cat_cliff.gif) |

This feature gives you precise control over your shot's composition by letting
you define the starting and ending frame. Upload an image or use a frame from a
previous video generation to make sure your scene begins and concludes exactly
as you envision it.

### Prompting for extension

To extend your Veo-generated video with Veo 3.1, use the video as an input along
with an optional text prompt. Extend finalizes the final second or 24 frames of
your video and continues the action.

Note that voice is not able to be effectively extended if it's not present in
the last 1 second of video.

| **Prompt** | **Generated output** |
|---|---|
| **Input video (Generated by Veo 3.1)** The paraglider takes off from the top of the mountain and starts gliding down the mountains overlooking the flower covered valleys below. | ![A paraglider takes off from the top of a mountain](https://storage.googleapis.com/generativeai-downloads/images/Paraglider.gif) |
| **Output Video (Generated by Veo 3.1)** Extend this video with the paraglider slowly descending. | ![A paraglider takes off from the top of a mountain, then slowly descends](https://storage.googleapis.com/generativeai-downloads/images/Paraglider_Extend.gif) |

### Example prompts and output

This section presents several prompts, highlighting how descriptive details can
elevate the outcome of each video.

#### Icicles

This video demonstrates how you can use the elements of
[prompt writing basics](https://ai.google.dev/gemini-api/docs/video#basics) in your prompt.

| **Prompt** | **Generated output** |
|---|---|
| Close up shot (composition) of melting icicles (subject) on a frozen rock wall (context) with cool blue tones (ambiance), zoomed in (camera motion) maintaining close-up detail of water drips (action). | ![Dripping icicles with a blue background.](https://storage.googleapis.com/generativeai-downloads/images/Icicles.gif) |

#### Man on the phone

These videos demonstrate how you can revise your prompt with increasingly
specific details to get Veo to refine the output to your liking.

| **Prompt** | **Generated output** |
|---|---|
| **Less detail** The camera dollies to show a close up of a desperate man in a green trench coat. He's making a call on a rotary-style wall phone with a green neon light. It looks like a movie scene. | ![Man talking on the phone.](https://storage.googleapis.com/generativeai-downloads/images/Desperate_Man.gif) |
| **More detail** A close-up cinematic shot follows a desperate man in a weathered green trench coat as he dials a rotary phone mounted on a gritty brick wall, bathed in the eerie glow of a green neon sign. The camera dollies in, revealing the tension in his jaw and the desperation etched on his face as he struggles to make the call. The shallow depth of field focuses on his furrowed brow and the black rotary phone, blurring the background into a sea of neon colors and indistinct shadows, creating a sense of urgency and isolation. | ![Man talking on the phone](https://storage.googleapis.com/generativeai-downloads/images/detail_call.gif) |

#### Snow leopard

| **Prompt** | **Generated output** |
|---|---|
| **Simple prompt:** A cute creature with snow leopard-like fur is walking in winter forest, 3D cartoon style render. | ![Snow leopard is lethargic.](https://storage.googleapis.com/generativeai-downloads/images/snowleopard.gif) |
| **Detailed prompt:** Create a short 3D animated scene in a joyful cartoon style. A cute creature with snow leopard-like fur, large expressive eyes, and a friendly, rounded form happily prances through a whimsical winter forest. The scene should feature rounded, snow-covered trees, gentle falling snowflakes, and warm sunlight filtering through the branches. The creature's bouncy movements and wide smile should convey pure delight. Aim for an upbeat, heartwarming tone with bright, cheerful colors and playful animation. | ![Snow leopard is running faster.](https://storage.googleapis.com/generativeai-downloads/images/snow-run.gif) |

### Examples by writing elements

These examples show you how to refine your prompts by each basic element.

#### Subject and context

Specify the main focus (subject) and the background or environment (context).

| **Prompt** | **Generated output** |
|---|---|
| An architectural rendering of a white concrete apartment building with flowing organic shapes, seamlessly blending with lush greenery and futuristic elements | ![Placeholder.](https://storage.googleapis.com/generativeai-downloads/images/architecture.gif) |
| A satellite floating through outer space with the moon and some stars in the background. | ![Satellite floating in the atmosphere.](https://storage.googleapis.com/generativeai-downloads/images/satellite.gif) |

#### Action

Specify what the subject is doing (e.g., walking, running, or turning their
head).

| **Prompt** | **Generated output** |
|---|---|
| A wide shot of a woman walking along the beach, looking content and relaxed towards the horizon at sunset. | ![Sunset is absolutely beautiful.](https://storage.googleapis.com/generativeai-downloads/images/sunset.gif) |

#### Style

Add keywords to steer the generation toward a specific aesthetic (e.g., surreal,
vintage, futuristic, film noir).

| **Prompt** | **Generated output** |
|---|---|
| Film noir style, man and woman walk on the street, mystery, cinematic, black and white. | ![Film noir style is absolutely beautiful.](https://storage.googleapis.com/generativeai-downloads/images/noir.gif) |

#### Camera motion and composition

Specify how the camera moves (POV shot, aerial view, tracking drone view) and
how the shot is framed (wide shot, close-up, low angle).

| **Prompt** | **Generated output** |
|---|---|
| A POV shot from a vintage car driving in the rain, Canada at night, cinematic. | ![Sunset is absolutely beautiful.](https://storage.googleapis.com/generativeai-downloads/images/car-pov.gif) |
| Extreme close-up of a an eye with city reflected in it. | ![Sunset is absolutely beautiful.](https://storage.googleapis.com/generativeai-downloads/images/eye.gif) |

#### Ambiance

Color palettes and lighting influence the mood. Try terms like "muted orange
warm tones," "natural light," "sunrise," or "cool blue tones."

| **Prompt** | **Generated output** |
|---|---|
| A close-up of a girl holding adorable golden retriever puppy in the park, sunlight. | ![A puppy in a young girl's arms.](https://ai.google.dev/static/gemini-api/docs/video/images/ambiance_puppy.gif) |
| Cinematic close-up shot of a sad woman riding a bus in the rain, cool blue tones, sad mood. | ![A woman riding on a bus that feels sad.](https://ai.google.dev/static/gemini-api/docs/video/images/ambiance_sad.gif) |

### Negative prompts

Negative prompts specify elements you *don't* want in the video.

-  Don't use instructive language like *no* or *don't*. (e.g., "No walls").
-  Do describe what you don't want to see. (e.g., "wall, frame").

| **Prompt** | **Generated output** |
|---|---|
| **Without Negative Prompt:** Generate a short, stylized animation of a large, solitary oak tree with leaves blowing vigorously in a strong wind... \[truncated\] | ![Tree with using words.](https://ai.google.dev/static/gemini-api/docs/video/images/tree_with_no_negative.gif) |
| **With Negative Prompt:** \[Same prompt\] <br /> Negative prompt: urban background, man-made structures, dark, stormy, or threatening atmosphere. | ![Tree with no negative words.](https://ai.google.dev/static/gemini-api/docs/video/images/tree_with_negative.gif) |

### Aspect ratios

Veo lets you specify the aspect ratio for your video.

| **Prompt** | **Generated output** |
|---|---|
| **Widescreen (16:9)** Create a video with a tracking drone view of a man driving a red convertible car in Palm Springs, 1970s, warm sunlight, long shadows. | ![A man driving a red convertible car in Palm Springs, 1970s style.](https://ai.google.dev/static/gemini-api/docs/video/images/widescreen_palm_springs.gif) |
| **Portrait (9:16)** Create a video highlighting the smooth motion of a majestic Hawaiian waterfall within a lush rainforest. Focus on realistic water flow, detailed foliage, and natural lighting to convey tranquility. Capture the rushing water, misty atmosphere, and dappled sunlight filtering through the dense canopy. Use smooth, cinematic camera movements to showcase the waterfall and its surroundings. Aim for a peaceful, realistic tone, transporting the viewer to the serene beauty of the Hawaiian rainforest. | ![A majestic Hawaiian waterfall in a lush rainforest.](https://ai.google.dev/static/gemini-api/docs/video/images/waterfall.gif) |

## Limitations

- **Request latency:** Min: 11 seconds; Max: 6 minutes (during peak hours).
- **Regional limitations:** In EU, UK, CH, MENA locations, the following are the allowed values for `personGeneration`:
  - Veo 3: `allow_adult` only.
  - Veo 2: `dont_allow` and `allow_adult`. Default is `dont_allow`.
- **Video retention:** Generated videos are stored on the server for 2 days, after which they are removed. To save a local copy, you must download your video within 2 days of generation. Extended videos are treated as newly generated videos.
- **Watermarking:** Videos created by Veo are watermarked using [SynthID](https://deepmind.google/technologies/synthid/), our tool for watermarking and identifying AI-generated content. Videos can be verified using the [SynthID](https://deepmind.google/science/synthid/) verification platform.
- **Safety:** Generated videos are passed through safety filters and memorization checking processes that help mitigate privacy, copyright and bias risks.
- **Audio error:** Veo 3.1 will sometimes block a video from generating because of safety filters or other processing issues with the audio. You will not be charged if your video is blocked from generating.

## Model features

| Feature | Description | Veo 3.1 \& Veo 3.1 Fast | Veo 3 \& Veo 3 Fast | Veo 2 |
|---|---|---|---|---|
| **Audio** | Natively generates audio with video. | Natively generates audio with video. |  Always on |  Silent only |
| **Input Modalities** | The type of input used for generation. | Text-to-Video, Image-to-Video, Video-to-Video | Text-to-Video, Image-to-Video | Text-to-Video, Image-to-Video |
| **Resolution** | The output resolution of the video. | 720p, 1080p (8s length only), 4k (8s length only) *720p only when using video extension.* | 720p \& 1080p (16:9 only) | 720p |
| **Frame Rate** | The output frame rate of the video. | 24fps | 24fps | 24fps |
| **Video Duration** | Length of the generated video. | 8 seconds, 6 seconds, 4 seconds *8 seconds only if 1080p or 4k or using reference images* | 8 seconds | 5-8 seconds |
| **Videos per Request** | Number of videos generated per request. | 1 | 1 | 1 or 2 |
| **Status \& Details** | Model availability and further details. | [Preview](https://ai.google.dev/gemini-api/docs/models#preview) | [Stable](https://ai.google.dev/gemini-api/docs/models#veo-3) | [Stable](https://ai.google.dev/gemini-api/docs/models#latest-stable) |

## Model versions

Check out the [Pricing](https://ai.google.dev/gemini-api/docs/pricing#veo-3.1) and [Rate limits](https://ai.google.dev/gemini-api/docs/rate-limits) pages for more Veo model-specific usage
details.

Veo Fast versions allow developers to create videos with sound while maintaining
high quality and optimizing for speed and business use cases. They're ideal for
backend services that programmatically generate ads, tools for rapid A/B testing
of creative concepts, or apps that need to quickly produce social media content.  

### Veo 3.1 Preview

| Property | Description |
|---|---|
| id_cardModel code | **Gemini API** `veo-3.1-generate-preview` |
| saveSupported data types | **Input** Text, Image **Output** Video with audio |
| token_autoLimits | **Text input** 1,024 tokens **Output video** 1 |
| calendar_monthLatest update | January 2026 |

### Veo 3.1 Fast Preview

| Property | Description |
|---|---|
| id_cardModel code | **Gemini API** `veo-3.1-fast-generate-preview` |
| saveSupported data types | **Input** Text, Image **Output** Video with audio |
| token_autoLimits | **Text input** 1,024 tokens **Output video** 1 |
| calendar_monthLatest update | September 2025 |

### Veo 2

| Property | Description |
|---|---|
| id_cardModel code | **Gemini API** `veo-2.0-generate-001` |
| saveSupported data types | **Input** Text, image **Output** Video |
| token_autoLimits | **Text input** N/A **Image input** Any image resolution and aspect ratio up to 20MB file size **Output video** Up to 2 |
| calendar_monthLatest update | April 2025 |

## What's next

- Get started with the Veo 3.1 API by experimenting in the [Veo Quickstart Colab](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_Veo.ipynb) and the [Veo 3.1 applet](https://aistudio.google.com/apps/bundled/veo_studio).
- Learn how to write even better prompts with our [Introduction to prompt design](https://ai.google.dev/gemini-api/docs/prompting-intro).
